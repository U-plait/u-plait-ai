from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.schemas import ChatTurnRequest
from app.core.jwt_auth import get_current_user_id
from app.core.database import get_db
from app.models.models import ChatLog
from app.service.rag_service import build_multi_turn_chain
from langchain_community.vectorstores.pgvector import PGVector
import os
import json
import asyncio
from langchain_openai import OpenAIEmbeddings
from fastapi.responses import StreamingResponse
from app.service.tag_service import update_user_tags
from langchain_community.embeddings import HuggingFaceEmbeddings
from app.core.vector_store import get_vector_store
from sqlalchemy import text

router = APIRouter()

@router.post("/chat")
async def chat_turn(
    request: ChatTurnRequest,
    db: Session = Depends(get_db),
    user_id: int = Depends(get_current_user_id)
):
    
    # 1. ì‚¬ìš©ì ì •ë³´ + ìƒìœ„ 2ê°œ íƒœê·¸ ì¡°íšŒ (Raw SQL)
    sql = text("""
        SELECT 
            u.name, u.age, u.gender,
            COALESCE(string_agg(t.name, ', ' ORDER BY ut.tag_count DESC), '') AS top_tags
        FROM users u
        LEFT JOIN user_tag ut ON u.id = ut.user_id
        LEFT JOIN tag t ON ut.tag_id = t.id
        WHERE u.id = :user_id
        GROUP BY u.id, u.name, u.age, u.gender
    """)

    result = db.execute(sql, {"user_id": user_id}).fetchone()

    if result:
        user_name, user_age, user_gender, top_tags = result

        # ì‚¬ìš©ì ì •ë³´ ë¬¸ìì—´ ìƒì„±
        if top_tags:
            user_info = f"ì‚¬ìš©ì ì´ë¦„: {user_name}, ë‚˜ì´: {user_age}, ì„±ë³„: {user_gender}, ì£¼ìš” ê´€ì‹¬ íƒœê·¸: {top_tags}"
        else:
            user_info = f"ì‚¬ìš©ì ì´ë¦„: {user_name}, ë‚˜ì´: {user_age}, ì„±ë³„: {user_gender}"
        
        # ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶œë ¥
        print(f"[DEBUG] ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì„±ê³µ: {user_info}")
    else:
        user_info = "ì‚¬ìš©ì ì •ë³´ ì—†ìŒ"
        print("[DEBUG] ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: í•´ë‹¹ IDì— ëŒ€í•œ ì •ë³´ ì—†ìŒ")

    # ì´ì „ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
    history = db.query(ChatLog).filter(ChatLog.user_id == user_id).order_by(ChatLog.created_at).all()
    history_pairs = []
    for i in range(0, len(history) -1, 2):
            question = history[i].log
            answer = history[i + 1].log
            history_pairs.append((question, answer))

    vectorstore = get_vector_store()

    # 2. ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥
    print("\nğŸ“š [Retrieved Documents]")
    docs_scores = vectorstore.similarity_search_with_score(request.query, k=5)
    print(f"\n[DEBUG] Retrieved {len(docs_scores)} documents.")
    for i, (doc, score) in enumerate(docs_scores):
        print(f"Rank {i+1}: Score={score:.3f} | {doc.page_content[:100]}")

    # LangChain chain ìƒì„±
    chain = build_multi_turn_chain()

    # ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
    async def gpt_stream():
         answer_buffer = ""  #GPT ë‹µë³€
         plan_json_buffer = ""   # plan_ids
         is_plan_mode = False  # [END_OF_MESSAGE] ì´í›„ plan_ids ì¡´ì¬ ì—¬ë¶€
    
         # LangChain chainì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ë©´ì„œ í† í° ë‹¨ìœ„ë¡œ ì‘ë‹µ ìˆ˜ì‹ 
         async for chunk in chain.astream({
              "question": request.query,
              "chat_history": history_pairs,
              "user_info": user_info
         }):

            # chunkê°€ dictì´ë©´ 'answer' í•„ë“œì—ì„œ ê°€ì ¸ì˜¤ê³ , ì•„ë‹ˆë©´ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
            token = chunk.get("answer", "") if isinstance(chunk, dict) else str(chunk)

            if "[END_OF_MESSAGE]" in token:
                is_plan_mode = True
                parts = token.split("[END_OF_MESSAGE]")

                # ë©”ì‹œì§€ ë¶€ë¶„ë§Œ ìŠ¤íŠ¸ë¦¬ë°
                answer_buffer += parts[0]
                for char in parts[0]:
                    yield f"data: {char}\n\n"
                    await asyncio.sleep(0.01)

                yield f"data: [END_OF_MESSAGE]\n\n"

                # JSONì´ ê°™ì´ ë¶™ì–´ì˜¨ ê²½ìš° ì €ì¥
                if len(parts) > 1:
                    plan_json_buffer += parts[1]
                    answer_buffer += "[END_OF_MESSAGE]" + parts[1]  # ğŸ”¥ ì—¬ê¸°ë¥¼ ì¶”ê°€
                continue

            # ì´ ì‹œì ì˜ tokenì€ [END_OF_MESSAGE] ì—†ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸
            if not is_plan_mode:
                answer_buffer += token
                for char in token:
                    yield f"data: {char}\n\n"
                    await asyncio.sleep(0.01)
            else:
                plan_json_buffer += token

        # plan_ids íŒŒì‹±
         try:
            plan_data = json.loads(plan_json_buffer.strip())
         except Exception:
            plan_data = {"plan_ids": []}

        # plan_ids JSONì„ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ (ì¶”í›„ì— ì´ê±° ê¸°ë°˜ìœ¼ë¡œ dbì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ê±¸ë¡œ ê³ ì³ì•¼í•¨)
         yield f"data: {json.dumps(plan_data)}\n\n"

         plan_ids = plan_data.get("plan_ids", [])
         plans_info = []
         if plan_ids:
            sql = text("""
                SELECT id, plan_name, plan_price, description, dtype
                FROM plan
                WHERE id = ANY(:plan_ids)
            """)
            result = db.execute(sql, {"plan_ids": plan_ids})
            plans_info = [dict(row) for row in result.mappings().all()]

            yield f"data: {json.dumps({'plans': plans_info})}\n\n"


        # ìœ ì € íƒœê·¸ ì—…ë°ì´íŠ¸ í˜¸ì¶œ ì¶”ê°€
         if plan_data.get("plan_ids"):
            update_user_tags(user_id=user_id, plan_ids=plan_data["plan_ids"], db=db)

        # ëŒ€í™” ë¡œê·¸ DBì— ì €ì¥ (ì§ˆë¬¸ + ë‹µë³€)
         db.add(ChatLog(user_id=user_id, log=request.query, is_chatbot=False))
         db.add(ChatLog(user_id=user_id, log=answer_buffer, is_chatbot=True))
         db.commit()
    return StreamingResponse(gpt_stream(), media_type="text/event-stream")